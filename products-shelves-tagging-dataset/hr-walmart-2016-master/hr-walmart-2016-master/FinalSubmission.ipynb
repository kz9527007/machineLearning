{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "label = pd.read_csv(\"data/label.csv\")\n",
    "print(label.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"data/test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(\"tag\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = pd.concat([train, test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seller_cnt = full[\"Seller\"].value_counts()\n",
    "selected_seller = seller_cnt[seller_cnt > 100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full.loc[~full[\"Seller\"].isin(selected_seller), \"Seller\"] = \"\"\n",
    "full.loc[:, \"Seller\"] = LabelEncoder().fit_transform(full[\"Seller\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full.loc[:, \"Actors\"] = ~full[\"Actors\"].isnull() * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Not Null: 501\n"
     ]
    }
   ],
   "source": [
    "print(\"# of Not Null:\", full[full[\"Actors\"]==1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ISBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full.loc[:, \"ISBN\"] = ~full[\"ISBN\"].isnull() * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Not Null: 534\n"
     ]
    }
   ],
   "source": [
    "print(\"# of Not Null:\", full[full[\"ISBN\"]==1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full.loc[:, \"Genre ID\"] = (full[\"Genre ID\"] == 5065) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Not Null: 149\n"
     ]
    }
   ],
   "source": [
    "print(\"# of Not Null:\", full[full[\"Genre ID\"]==1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Item Class ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_class_cnt = full[\"Item Class ID\"].value_counts()\n",
    "selected_item_class = item_class_cnt[item_class_cnt > 100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full.loc[~full[\"Item Class ID\"].isin(selected_item_class), \"Item Class ID\"] = \"\"\n",
    "full.loc[:, \"Item Class ID\"] = LabelEncoder().fit_transform(full[\"Item Class ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Recommended Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full.loc[:, \"Recommended Location\"] = ~full[\"Recommended Location\"].isnull() * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Not Null: 224\n"
     ]
    }
   ],
   "source": [
    "print(\"# of Not Null:\", full[full[\"Recommended Location\"]==1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare MPAA Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpaa_cnt = full[\"MPAA Rating\"].value_counts()\n",
    "selected_mpaa = mpaa_cnt[mpaa_cnt > 100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full.loc[~full[\"MPAA Rating\"].isin(selected_mpaa), \"MPAA Rating\"] = \"\"\n",
    "full.loc[:, \"MPAA Rating\"] = LabelEncoder().fit_transform(full[\"MPAA Rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Recommend Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_uses = [\"Television\", \"LCD display\", \"Televison\", \"2 LCD / plasma panels\", \"TV\", \"Flat Panel Display\",\n",
    "                \"LCD / plasma panel\", \"LCD TV\", \"Office, Home, Televisions\", \"Plasma / LCD / TV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full[\"TV\"] = 0\n",
    "full.loc[full[\"Recommended Use\"].isin(selected_uses), \"TV\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Not Null: 460\n"
     ]
    }
   ],
   "source": [
    "print(\"# of Not Null:\", full[full[\"TV\"]==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_columns = ['Seller', 'Actors', 'Genre ID', 'ISBN', \n",
    "                     'Item Class ID', 'MPAA Rating',\n",
    "                     'Recommended Location', 'TV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = full.loc[:(train.shape[0]-1),selected_columns]\n",
    "test_dataset = full.loc[train.shape[0]:,selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_encoded = pd.get_dummies(full[selected_columns], columns=[\"Seller\", \"MPAA Rating\", \"Item Class ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_names = label.columns.tolist()\n",
    "label_names.remove(\"item_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_f1_score(threshold, y_true, y_prob):\n",
    "    return f1_score(y_true, (y_prob >= threshold) * 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "tag_pattern = re.compile(r'<.+?>')\n",
    "full[\"SD\"] = full[\"Short Description\"].apply(\n",
    "    lambda x: \"\" if not isinstance(x, str) or x == \"short description is not available\" else tag_pattern.sub('', x))\n",
    "full[\"PSD\"] = full[\"Product Short Description\"].apply(\n",
    "    lambda x: \"\" if not isinstance(x, str) or x == \"short description is not available\" else tag_pattern.sub('', x))\n",
    "full[\"PLD\"] = full[\"Product Long Description\"].apply(\n",
    "    lambda x: \"\" if not isinstance(x, str) or x == \"short description is not available\" else tag_pattern.sub('', x))\n",
    "full.loc[full[\"Product Name\"] == full[\"PSD\"], \"PSD\"] = \"\"\n",
    "full.loc[full[\"PSD\"].isnull(), \"PSD\"] = \"\"\n",
    "full.loc[full[\"Product Name\"] == full[\"SD\"], \"SD\"] = \"\"\n",
    "full.loc[full[\"SD\"].isnull(), \"SD\"] = \"\"\n",
    "full.loc[full[\"Product Name\"] == full[\"PLD\"], \"PLD\"] = \"\"\n",
    "full.loc[full[\"PLD\"].isnull(), \"PLD\"] = \"\"\n",
    "full.loc[full[\"Synopsis\"].isnull(), \"Synopsis\"] = \"\"\n",
    "full[\"Full Text\"] = full[\"Product Name\"] + \" \" + full[\"SD\"] + \" \" + full[\"PLD\"] + \" \" + full[\"Synopsis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_COLUMN = \"Full Text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full.loc[full[TARGET_COLUMN].isnull(), TARGET_COLUMN] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(max_features=5000, ngram_range=(1,3), analyzer=\"word\", \n",
    "                      stop_words=\"english\", norm=\"l2\").fit(full[TARGET_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now mix with the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_name_features = pd.DataFrame(vec.transform(full.loc[:, TARGET_COLUMN]).todense(), columns=vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Bags of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 960 (CNMeM is enabled with initial size: 50.0% of memory, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10593, 5038)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.concat([full_encoded.iloc[:train.shape[0]], \n",
    "                           product_name_features.iloc[:train.shape[0]]], axis=1)\n",
    "test_dataset = pd.concat([full_encoded.iloc[train.shape[0]:], \n",
    "                           product_name_features.iloc[train.shape[0]:]], axis=1)\n",
    "# scaler = MinMaxScaler()\n",
    "# train_dataset = pd.DataFrame(scaler.fit_transform(train_dataset),\n",
    "#                              columns = train_dataset.columns)\n",
    "# test_dataset = pd.DataFrame(scaler.transform(test_dataset),\n",
    "#                              columns = test_dataset.columns)\n",
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bow_model(input_shape, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(768, input_shape=input_shape))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        # optimizer=SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=1.),\n",
    "        optimizer=\"Adadelta\",\n",
    "        metrics=['fbeta_score'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full prediction in one Model\n",
    "Do CV first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8474 samples, validate on 2119 samples\n",
      "Epoch 1/20\n",
      "2s - loss: 0.6734 - fbeta_score: 0.1710 - val_loss: 0.2050 - val_fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1669 - fbeta_score: 0.4929 - val_loss: 0.1172 - val_fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0919 - fbeta_score: 0.6314 - val_loss: 0.0676 - val_fbeta_score: 0.6536\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0729 - fbeta_score: 0.6903 - val_loss: 0.0576 - val_fbeta_score: 0.7524\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0642 - fbeta_score: 0.7365 - val_loss: 0.0542 - val_fbeta_score: 0.7721\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0568 - fbeta_score: 0.7620 - val_loss: 0.0531 - val_fbeta_score: 0.7786\n",
      "Epoch 7/20\n",
      "2s - loss: 0.0516 - fbeta_score: 0.7841 - val_loss: 0.0509 - val_fbeta_score: 0.7869\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0475 - fbeta_score: 0.8011 - val_loss: 0.0504 - val_fbeta_score: 0.7910\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0442 - fbeta_score: 0.8112 - val_loss: 0.0506 - val_fbeta_score: 0.7925\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0410 - fbeta_score: 0.8252 - val_loss: 0.0503 - val_fbeta_score: 0.7988\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0380 - fbeta_score: 0.8418 - val_loss: 0.0510 - val_fbeta_score: 0.7920\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0356 - fbeta_score: 0.8509 - val_loss: 0.0505 - val_fbeta_score: 0.7991\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0339 - fbeta_score: 0.8579 - val_loss: 0.0504 - val_fbeta_score: 0.8016\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0313 - fbeta_score: 0.8689 - val_loss: 0.0520 - val_fbeta_score: 0.7984\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0295 - fbeta_score: 0.8750 - val_loss: 0.0522 - val_fbeta_score: 0.8065\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0276 - fbeta_score: 0.8857 - val_loss: 0.0521 - val_fbeta_score: 0.8042\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0261 - fbeta_score: 0.8913 - val_loss: 0.0524 - val_fbeta_score: 0.8084\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0245 - fbeta_score: 0.8992 - val_loss: 0.0531 - val_fbeta_score: 0.8076\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0226 - fbeta_score: 0.9056 - val_loss: 0.0544 - val_fbeta_score: 0.8062\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0215 - fbeta_score: 0.9115 - val_loss: 0.0548 - val_fbeta_score: 0.8122\n",
      "Train on 8474 samples, validate on 2119 samples\n",
      "Epoch 1/20\n",
      "2s - loss: 0.6755 - fbeta_score: 0.1691 - val_loss: 0.1924 - val_fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1653 - fbeta_score: 0.4880 - val_loss: 0.1222 - val_fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0928 - fbeta_score: 0.6307 - val_loss: 0.0683 - val_fbeta_score: 0.6351\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0746 - fbeta_score: 0.6932 - val_loss: 0.0552 - val_fbeta_score: 0.7582\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0647 - fbeta_score: 0.7346 - val_loss: 0.0518 - val_fbeta_score: 0.7761\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0586 - fbeta_score: 0.7566 - val_loss: 0.0502 - val_fbeta_score: 0.7806\n",
      "Epoch 7/20\n",
      "2s - loss: 0.0530 - fbeta_score: 0.7800 - val_loss: 0.0476 - val_fbeta_score: 0.7997\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0486 - fbeta_score: 0.7940 - val_loss: 0.0470 - val_fbeta_score: 0.8086\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0455 - fbeta_score: 0.8056 - val_loss: 0.0462 - val_fbeta_score: 0.8107\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0419 - fbeta_score: 0.8214 - val_loss: 0.0456 - val_fbeta_score: 0.8143\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0394 - fbeta_score: 0.8330 - val_loss: 0.0455 - val_fbeta_score: 0.8195\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0362 - fbeta_score: 0.8452 - val_loss: 0.0461 - val_fbeta_score: 0.8233\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0345 - fbeta_score: 0.8561 - val_loss: 0.0460 - val_fbeta_score: 0.8174\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0318 - fbeta_score: 0.8644 - val_loss: 0.0468 - val_fbeta_score: 0.8186\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0301 - fbeta_score: 0.8736 - val_loss: 0.0474 - val_fbeta_score: 0.8159\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0282 - fbeta_score: 0.8829 - val_loss: 0.0476 - val_fbeta_score: 0.8196\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0268 - fbeta_score: 0.8882 - val_loss: 0.0477 - val_fbeta_score: 0.8219\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0248 - fbeta_score: 0.8971 - val_loss: 0.0493 - val_fbeta_score: 0.8216\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0232 - fbeta_score: 0.9036 - val_loss: 0.0495 - val_fbeta_score: 0.8220\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0224 - fbeta_score: 0.9070 - val_loss: 0.0505 - val_fbeta_score: 0.8213\n",
      "Train on 8474 samples, validate on 2119 samples\n",
      "Epoch 1/20\n",
      "2s - loss: 0.6719 - fbeta_score: 0.1708 - val_loss: 0.1893 - val_fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1655 - fbeta_score: 0.4940 - val_loss: 0.1205 - val_fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0920 - fbeta_score: 0.6329 - val_loss: 0.0690 - val_fbeta_score: 0.6230\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0737 - fbeta_score: 0.6962 - val_loss: 0.0565 - val_fbeta_score: 0.7538\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0643 - fbeta_score: 0.7360 - val_loss: 0.0528 - val_fbeta_score: 0.7761\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0583 - fbeta_score: 0.7559 - val_loss: 0.0514 - val_fbeta_score: 0.7778\n",
      "Epoch 7/20\n",
      "2s - loss: 0.0519 - fbeta_score: 0.7833 - val_loss: 0.0497 - val_fbeta_score: 0.7961\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0482 - fbeta_score: 0.7977 - val_loss: 0.0492 - val_fbeta_score: 0.7947\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0451 - fbeta_score: 0.8083 - val_loss: 0.0487 - val_fbeta_score: 0.8038\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0420 - fbeta_score: 0.8246 - val_loss: 0.0481 - val_fbeta_score: 0.8066\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0386 - fbeta_score: 0.8383 - val_loss: 0.0486 - val_fbeta_score: 0.8059\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0360 - fbeta_score: 0.8500 - val_loss: 0.0483 - val_fbeta_score: 0.8086\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0339 - fbeta_score: 0.8595 - val_loss: 0.0487 - val_fbeta_score: 0.8084\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0317 - fbeta_score: 0.8658 - val_loss: 0.0495 - val_fbeta_score: 0.8098\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0299 - fbeta_score: 0.8745 - val_loss: 0.0493 - val_fbeta_score: 0.8083\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0283 - fbeta_score: 0.8817 - val_loss: 0.0498 - val_fbeta_score: 0.8158\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0264 - fbeta_score: 0.8916 - val_loss: 0.0507 - val_fbeta_score: 0.8120\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0247 - fbeta_score: 0.8956 - val_loss: 0.0516 - val_fbeta_score: 0.8101\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0228 - fbeta_score: 0.9056 - val_loss: 0.0525 - val_fbeta_score: 0.8161\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0217 - fbeta_score: 0.9103 - val_loss: 0.0537 - val_fbeta_score: 0.8134\n",
      "Train on 8475 samples, validate on 2118 samples\n",
      "Epoch 1/20\n",
      "2s - loss: 0.6717 - fbeta_score: 0.1725 - val_loss: 0.2226 - val_fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1657 - fbeta_score: 0.4941 - val_loss: 0.1190 - val_fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0913 - fbeta_score: 0.6348 - val_loss: 0.0725 - val_fbeta_score: 0.6347\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0725 - fbeta_score: 0.6962 - val_loss: 0.0610 - val_fbeta_score: 0.7445\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0632 - fbeta_score: 0.7388 - val_loss: 0.0576 - val_fbeta_score: 0.7580\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0563 - fbeta_score: 0.7645 - val_loss: 0.0553 - val_fbeta_score: 0.7758\n",
      "Epoch 7/20\n",
      "2s - loss: 0.0519 - fbeta_score: 0.7815 - val_loss: 0.0546 - val_fbeta_score: 0.7803\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0476 - fbeta_score: 0.7961 - val_loss: 0.0536 - val_fbeta_score: 0.7837\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0434 - fbeta_score: 0.8174 - val_loss: 0.0536 - val_fbeta_score: 0.7891\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0400 - fbeta_score: 0.8284 - val_loss: 0.0524 - val_fbeta_score: 0.7906\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0383 - fbeta_score: 0.8365 - val_loss: 0.0525 - val_fbeta_score: 0.7970\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0353 - fbeta_score: 0.8503 - val_loss: 0.0536 - val_fbeta_score: 0.7981\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0331 - fbeta_score: 0.8611 - val_loss: 0.0536 - val_fbeta_score: 0.7985\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0309 - fbeta_score: 0.8698 - val_loss: 0.0540 - val_fbeta_score: 0.8026\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0291 - fbeta_score: 0.8776 - val_loss: 0.0535 - val_fbeta_score: 0.8010\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0274 - fbeta_score: 0.8852 - val_loss: 0.0543 - val_fbeta_score: 0.7992\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0255 - fbeta_score: 0.8937 - val_loss: 0.0560 - val_fbeta_score: 0.8044\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0242 - fbeta_score: 0.9011 - val_loss: 0.0557 - val_fbeta_score: 0.8065\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0219 - fbeta_score: 0.9066 - val_loss: 0.0572 - val_fbeta_score: 0.8061\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0209 - fbeta_score: 0.9117 - val_loss: 0.0576 - val_fbeta_score: 0.8090\n",
      "Train on 8475 samples, validate on 2118 samples\n",
      "Epoch 1/20\n",
      "2s - loss: 0.6687 - fbeta_score: 0.1761 - val_loss: 0.2889 - val_fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1659 - fbeta_score: 0.4959 - val_loss: 0.1178 - val_fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0901 - fbeta_score: 0.6390 - val_loss: 0.0675 - val_fbeta_score: 0.6644\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0733 - fbeta_score: 0.6955 - val_loss: 0.0581 - val_fbeta_score: 0.7515\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0626 - fbeta_score: 0.7390 - val_loss: 0.0546 - val_fbeta_score: 0.7739\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0571 - fbeta_score: 0.7638 - val_loss: 0.0524 - val_fbeta_score: 0.7869\n",
      "Epoch 7/20\n",
      "1s - loss: 0.0520 - fbeta_score: 0.7826 - val_loss: 0.0498 - val_fbeta_score: 0.7934\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0479 - fbeta_score: 0.8019 - val_loss: 0.0495 - val_fbeta_score: 0.7951\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0440 - fbeta_score: 0.8114 - val_loss: 0.0493 - val_fbeta_score: 0.8032\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0405 - fbeta_score: 0.8290 - val_loss: 0.0484 - val_fbeta_score: 0.8019\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0384 - fbeta_score: 0.8378 - val_loss: 0.0482 - val_fbeta_score: 0.8030\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0363 - fbeta_score: 0.8473 - val_loss: 0.0485 - val_fbeta_score: 0.8075\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0338 - fbeta_score: 0.8601 - val_loss: 0.0483 - val_fbeta_score: 0.8099\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0320 - fbeta_score: 0.8645 - val_loss: 0.0486 - val_fbeta_score: 0.8097\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0300 - fbeta_score: 0.8750 - val_loss: 0.0498 - val_fbeta_score: 0.8067\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0286 - fbeta_score: 0.8794 - val_loss: 0.0501 - val_fbeta_score: 0.8087\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0264 - fbeta_score: 0.8891 - val_loss: 0.0501 - val_fbeta_score: 0.8089\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0247 - fbeta_score: 0.8956 - val_loss: 0.0523 - val_fbeta_score: 0.8084\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0231 - fbeta_score: 0.9047 - val_loss: 0.0521 - val_fbeta_score: 0.8093\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0216 - fbeta_score: 0.9097 - val_loss: 0.0523 - val_fbeta_score: 0.8112\n",
      "4537 0.874697195831 0.0014832385966\n",
      "4483 0.869628771108 0.0140898588964\n",
      "106546 0.780436948883 0.00777340578\n",
      "581514 0.905873426379 0.017605141463\n",
      "1229821 0.85233649265 0.0164895577548\n",
      "95987 0.701043036472 0.00958237904991\n",
      "447913 0.61957755392 0.0273121291843\n",
      "522484 0.822374137558 0.00848619832925\n",
      "529295 0.929446125483 0.0282442647891\n",
      "127175 0.709153259551 0.0270651242646\n",
      "1229817 0.803164828394 0.0318381017311\n",
      "3304195 0.834085058505 0.017746482975\n",
      "5065 0.855055499414 0.00957183557902\n",
      "1180168 0.929615811991 0.0268051320798\n",
      "4538 0.844440243954 0.0288945971784\n",
      "4536 0.822525677951 0.0361989506212\n",
      "650659 0.849793139903 0.0150474703942\n",
      "1229820 0.809965146298 0.0263779751367\n",
      "1070524 0.647414855478 0.0615300271433\n",
      "1229819 0.566956521739 0.144606721215\n",
      "1225174 0.65706539075 0.0650929070966\n",
      "1071165 0.647255120554 0.125774727573\n",
      "1085065 0.682991534083 0.0769931496634\n",
      "1229825 0.752243051067 0.0988506269852\n",
      "62056 0.309210789211 0.0935298613279\n",
      "4457 0.376212121212 0.0754168093541\n",
      "1084835 0.793333333333 0.193677853951\n",
      "Overall score: 0.749847965618 0.16437249334\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "scores = []\n",
    "np.random.seed(888)\n",
    "thresholds, scores = defaultdict(list), defaultdict(list)\n",
    "skf = StratifiedKFold(n_splits=5, random_state=888, shuffle=True)\n",
    "for train_index, val_index in skf.split(train_dataset.values, label[\"4537\"]):\n",
    "    model = get_bow_model((train_dataset.shape[1],), label.shape[1]-1)\n",
    "    model.fit(train_dataset.iloc[train_index].values, \n",
    "              label.drop([\"item_id\"], axis=1).iloc[train_index].values,\n",
    "              validation_data=(\n",
    "                  train_dataset.iloc[val_index].values,\n",
    "                  label.drop([\"item_id\"], axis=1).iloc[val_index].values\n",
    "              ),\n",
    "              batch_size=32, nb_epoch=20, verbose=2)\n",
    "    pred = model.predict(train_dataset.iloc[val_index].values)\n",
    "    for i in range(1, label.shape[1]):\n",
    "        best_score, best_threshold = get_f1_score(0, label.iloc[val_index, i], pred[:, i-1]), 0\n",
    "        for threshold in np.arange(min(pred[:, i-1]), max(pred[:, i-1]), 0.01):\n",
    "            tmp_score = get_f1_score(threshold, label.iloc[val_index, i], pred[:, i-1])\n",
    "            if tmp_score > best_score:\n",
    "                best_score, best_threshold = tmp_score, threshold\n",
    "        thresholds[label.columns[i]].append(best_threshold)\n",
    "        scores[label.columns[i]].append(best_score)\n",
    "for target_label in label_names:\n",
    "    print(target_label, np.mean(scores[target_label]), np.std(scores[target_label]))\n",
    "print(\"Overall score:\", np.mean([x for x in scores.values()]), \n",
    "      np.std([x for x in scores.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall score: 0.749847965618 0.16437249334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2s - loss: 0.5822 - fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1242 - fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0814 - fbeta_score: nan\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0677 - fbeta_score: nan\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0589 - fbeta_score: nan\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0533 - fbeta_score: nan\n",
      "Epoch 7/20\n",
      "2s - loss: 0.0487 - fbeta_score: nan\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0452 - fbeta_score: nan\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0426 - fbeta_score: nan\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0393 - fbeta_score: nan\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0368 - fbeta_score: nan\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0349 - fbeta_score: nan\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0326 - fbeta_score: nan\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0300 - fbeta_score: nan\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0289 - fbeta_score: nan\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0273 - fbeta_score: nan\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0255 - fbeta_score: nan\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0240 - fbeta_score: nan\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0228 - fbeta_score: nan\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0219 - fbeta_score: nan\n",
      "Epoch 1/20\n",
      "2s - loss: 0.5855 - fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1248 - fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0810 - fbeta_score: nan\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0675 - fbeta_score: nan\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0589 - fbeta_score: nan\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0535 - fbeta_score: nan\n",
      "Epoch 7/20\n",
      "2s - loss: 0.0491 - fbeta_score: nan\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0451 - fbeta_score: nan\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0426 - fbeta_score: nan\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0399 - fbeta_score: nan\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0371 - fbeta_score: nan\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0344 - fbeta_score: nan\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0328 - fbeta_score: nan\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0308 - fbeta_score: nan\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0293 - fbeta_score: nan\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0272 - fbeta_score: nan\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0257 - fbeta_score: nan\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0239 - fbeta_score: nan\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0223 - fbeta_score: nan\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0220 - fbeta_score: nan\n",
      "Epoch 1/20\n",
      "2s - loss: 0.5866 - fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1239 - fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0806 - fbeta_score: nan\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0667 - fbeta_score: nan\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0589 - fbeta_score: nan\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0526 - fbeta_score: nan\n",
      "Epoch 7/20\n",
      "2s - loss: 0.0485 - fbeta_score: nan\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0451 - fbeta_score: nan\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0415 - fbeta_score: nan\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0398 - fbeta_score: nan\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0373 - fbeta_score: nan\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0346 - fbeta_score: nan\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0324 - fbeta_score: nan\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0304 - fbeta_score: nan\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0284 - fbeta_score: nan\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0270 - fbeta_score: nan\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0256 - fbeta_score: nan\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0241 - fbeta_score: nan\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0226 - fbeta_score: nan\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0212 - fbeta_score: nan\n",
      "Epoch 1/20\n",
      "2s - loss: 0.5890 - fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1227 - fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0801 - fbeta_score: nan\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0666 - fbeta_score: nan\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0592 - fbeta_score: nan\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0531 - fbeta_score: nan\n",
      "Epoch 7/20\n",
      "2s - loss: 0.0488 - fbeta_score: nan\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0455 - fbeta_score: nan\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0422 - fbeta_score: nan\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0395 - fbeta_score: nan\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0371 - fbeta_score: nan\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0346 - fbeta_score: nan\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0326 - fbeta_score: nan\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0306 - fbeta_score: nan\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0285 - fbeta_score: nan\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0275 - fbeta_score: nan\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0253 - fbeta_score: nan\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0244 - fbeta_score: nan\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0222 - fbeta_score: nan\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0221 - fbeta_score: nan\n",
      "Epoch 1/20\n",
      "2s - loss: 0.5865 - fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1257 - fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0808 - fbeta_score: nan\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0665 - fbeta_score: nan\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0597 - fbeta_score: nan\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0532 - fbeta_score: nan\n",
      "Epoch 7/20\n",
      "2s - loss: 0.0495 - fbeta_score: nan\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0457 - fbeta_score: nan\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0426 - fbeta_score: nan\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0397 - fbeta_score: nan\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0371 - fbeta_score: nan\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0351 - fbeta_score: nan\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0330 - fbeta_score: nan\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0311 - fbeta_score: nan\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0293 - fbeta_score: nan\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0278 - fbeta_score: nan\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0257 - fbeta_score: nan\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0245 - fbeta_score: nan\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0232 - fbeta_score: nan\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0224 - fbeta_score: nan\n",
      "Epoch 1/20\n",
      "2s - loss: 0.5934 - fbeta_score: nan\n",
      "Epoch 2/20\n",
      "2s - loss: 0.1243 - fbeta_score: nan\n",
      "Epoch 3/20\n",
      "2s - loss: 0.0806 - fbeta_score: nan\n",
      "Epoch 4/20\n",
      "2s - loss: 0.0665 - fbeta_score: nan\n",
      "Epoch 5/20\n",
      "2s - loss: 0.0590 - fbeta_score: nan\n",
      "Epoch 6/20\n",
      "2s - loss: 0.0536 - fbeta_score: nan\n",
      "Epoch 7/20\n",
      "2s - loss: 0.0496 - fbeta_score: nan\n",
      "Epoch 8/20\n",
      "2s - loss: 0.0454 - fbeta_score: nan\n",
      "Epoch 9/20\n",
      "2s - loss: 0.0426 - fbeta_score: nan\n",
      "Epoch 10/20\n",
      "2s - loss: 0.0397 - fbeta_score: nan\n",
      "Epoch 11/20\n",
      "2s - loss: 0.0370 - fbeta_score: nan\n",
      "Epoch 12/20\n",
      "2s - loss: 0.0345 - fbeta_score: nan\n",
      "Epoch 13/20\n",
      "2s - loss: 0.0330 - fbeta_score: nan\n",
      "Epoch 14/20\n",
      "2s - loss: 0.0306 - fbeta_score: nan\n",
      "Epoch 15/20\n",
      "2s - loss: 0.0284 - fbeta_score: nan\n",
      "Epoch 16/20\n",
      "2s - loss: 0.0268 - fbeta_score: nan\n",
      "Epoch 17/20\n",
      "2s - loss: 0.0255 - fbeta_score: nan\n",
      "Epoch 18/20\n",
      "2s - loss: 0.0243 - fbeta_score: nan\n",
      "Epoch 19/20\n",
      "2s - loss: 0.0230 - fbeta_score: nan\n",
      "Epoch 20/20\n",
      "2s - loss: 0.0215 - fbeta_score: nan\n"
     ]
    }
   ],
   "source": [
    "pred = None\n",
    "N_BAGGING = 6\n",
    "for seed in range(N_BAGGING):\n",
    "    np.random.seed(seed+888)\n",
    "    model = get_bow_model((train_dataset.shape[1],), label.shape[1]-1)\n",
    "    model.fit(train_dataset.values, \n",
    "              label.drop([\"item_id\"], axis=1).values,\n",
    "              batch_size=32, nb_epoch=20, verbose=2)\n",
    "    pred = model.predict(test_dataset.values) if pred is None else pred + model.predict(test_dataset.values)\n",
    "pred /= N_BAGGING\n",
    "prediction = pd.concat([test[[\"item_id\"]], pd.DataFrame(pred, columns=label.drop([\"item_id\"], axis=1).columns)],\n",
    "                       axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_prediction(row):    \n",
    "    result = []\n",
    "    for target_label in label_names:\n",
    "        if row[target_label] >= np.median(thresholds[target_label]):\n",
    "            result.append(target_label)    \n",
    "    # if len(result) == 0:\n",
    "    #     result.append(max([(x, row[x]) for x in label_names], key=lambda x:x[1])[0])\n",
    "    return \"[\" + \", \".join(result) + \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                [581514]\n",
       "1                                  [4537]\n",
       "2                                  [4483]\n",
       "3                                  [4483]\n",
       "4                                  [4537]\n",
       "5                                  [4537]\n",
       "6                                  [4483]\n",
       "7                                  [4537]\n",
       "8                                [581514]\n",
       "9                                  [4537]\n",
       "10                               [581514]\n",
       "11                [106546, 95987, 522484]\n",
       "12                         [522484, 4457]\n",
       "13                               [106546]\n",
       "14                                 [4483]\n",
       "15                               [529295]\n",
       "16                                 [4483]\n",
       "17                      [1229821, 447913]\n",
       "18                               [581514]\n",
       "19                                 [4483]\n",
       "20       [106546, 95987, 522484, 3304195]\n",
       "21                      [1229821, 447913]\n",
       "22                               [581514]\n",
       "23                                [95987]\n",
       "24                     [1229821, 1229820]\n",
       "25                                 [4537]\n",
       "26                               [529295]\n",
       "27                                 [4483]\n",
       "28                               [581514]\n",
       "29                              [1229821]\n",
       "                       ...               \n",
       "10563                              [4537]\n",
       "10564                           [1229821]\n",
       "10565                              [4537]\n",
       "10566                             [95987]\n",
       "10567                              [4537]\n",
       "10568                              [4483]\n",
       "10569                              [4537]\n",
       "10570                              [4537]\n",
       "10571                  [1229821, 1180168]\n",
       "10572             [106546, 95987, 522484]\n",
       "10573                    [106546, 522484]\n",
       "10574                   [1229821, 447913]\n",
       "10575                                  []\n",
       "10576                              [4483]\n",
       "10577                              [4538]\n",
       "10578                      [5065, 650659]\n",
       "10579                              [4483]\n",
       "10580                              [4537]\n",
       "10581                              [4483]\n",
       "10582                      [5065, 650659]\n",
       "10583                              [4483]\n",
       "10584                              [4537]\n",
       "10585                              [4537]\n",
       "10586                             [95987]\n",
       "10587                              [4483]\n",
       "10588                            [581514]\n",
       "10589                    [106546, 522484]\n",
       "10590                              [4537]\n",
       "10591                           [1180168]\n",
       "10592                           [1229821]\n",
       "Name: tag, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = prediction.assign(tag = prediction.apply(generate_prediction, axis=1))\n",
    "prediction[\"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction[[\"item_id\", \"tag\"]].to_csv(\"tags.tsv\",sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ds3]",
   "language": "python",
   "name": "conda-env-ds3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
